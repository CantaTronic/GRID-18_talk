\documentclass[18pt]{beamer}
\usepackage{templates/beamerthemekit}
\titlelogo{empty_logo}

\title[Cosmic rays data center]{Current status of data center for cosmic rays \\based on KCDC}
\subtitle{GRID-2018, Dubna}
\author{Dmitriy Kostunin, Victoria Tokareva}

\institute{Institute for Nuclear Physics (IKP)}

\date{September 12, 2018}

% Bibliography

\usepackage[citestyle=authoryear,bibstyle=numeric,hyperref,backend=biber]{biblatex}
\addbibresource{templates/example.bib}
\bibhang1em

\newcommand{\itemarrow}{\scriptsize\raise1.25pt\hbox{\textcolor{kit-green100}{$\blacktriangleright$}}}
\newcommand{\concl}[1]{\item[\itemarrow]\textcolor{kit-green100}{#1}}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\newlength{\cellwidth}
\setlength{\cellwidth}{0.43\textwidth}
\newcommand{\cellbox}[1]{\parbox{\cellwidth}{\vspace{1ex}#1\vspace{1ex}}}

\begin{document}

% change the following line to "ngerman" for German style date and logos
\selectlanguage{english}

%INTRODUCTION
\input{intro.tex}

% \section{The project objectives}
\section{The data integration approach}

\begin{frame}{The project objectives}
% Work packages:

\vspace{-1.5em}
\begin{center}
\includegraphics[width=0.82\textwidth]{pics/proj_objectives.png}
\end{center}

%proj_objectives.png
% \textcolor{red}{Add the 'data flow' scheme!!!}
% \begin{itemize}
%  \item Astroparticle data center (based on KCDC)
%  \item Software for big data processing (“Data Life Cycle Lab”)
%  \item Multimessenger data analysis and mapping
%  \item Go for the public ( astroparticle.online )
% \end{itemize}
\end{frame}

\begin{frame}{Deep into KASCADE and Tunka data formats}
\vspace{-2em}
\begin{minipage}[t]{0.48\textwidth}
  \begin{block}{Different}
    \begin{itemize}
      \item Data format (depends on avalilable detectors)
%         \item Information on detector properties (e.g.\ calibrations)
      \item Dedicated software for analyzing data
      \item Special system environment for the software
    \end{itemize}
  \end{block}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
  \begin{block}{Common}
    \begin{itemize}
      \item Metadata format (e.g.\ time, location, atmospheric conditions)
      \item Software for EAS simulation (e.g. KORSIKA)
      \item Shower parameters
      \item Theoretical models
    \end{itemize}
  \end{block}
\end{minipage}

%  \begin{exampleblock}{title}
%   text
%  \end{exampleblock}

\begin{minipage}[t]{0.48\textwidth}
  \begin{exampleblock}{Current state}
    \begin{itemize}
      \item Separate APIs and UIs for different experiments
    \end{itemize}
  \end{exampleblock}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
  \begin{exampleblock}{Our objective}
    \begin{itemize}
      \item Unified API and UIs for different experiments
    \end{itemize}
  \end{exampleblock}
\end{minipage}
\end{frame}

\begin{frame}{WMS~--- workload management system}
% \textcolor{red}{\textit{Taken from Petrosyan's talk}}
\begin{itemize}
  \item The basic idea is to provide a central queue for all users and make all the distributed sites look like local ones;
  \item Starting from mid 90's are widely used in collider experiments (AliEn, Dirac, PanDA);
  \item Dedicated for:
  \begin{itemize}
  \item Unified usage of the distributed remote data and common data analysis;
  \item Conceal various low-level software and provide unified high-level interface;
  \end{itemize}
%   \item
%   Hide middleware while supporting diversity and evolution
%   \begin{itemize}
%     \item WMS interacts with middleware, users see only high level workflow
%     \item Automation engines built in WMS, not exposed to users
%   \end{itemize}
  \item Provide the common way to issue tasks to different types of the distibuted sites;
  \item
%   Use the same system for simulation, data processing and users analysis
  The same system for the data access, analysis and simulation.
%   \item Similar ideas have been implemented in several independent systems developed by LHC experiments: AliEn, Dirac, PanDA
\end{itemize}
\end{frame}

\begin{frame}{Data-oriented approach}
% \vspace{-1em}
What data do we work with?

% \vspace{3em}

\parbox{0.48\textwidth}{
\begin{itemize}
  \item Data types:
  \begin{itemize}
    \item Raw detector readouts;
    \item Pre-analyzed events;
    \item Metadata
  \end{itemize}
\end{itemize}
}
\hfill
\parbox{0.48\textwidth}{
\begin{itemize}
  \item Data structure:
  \begin{itemize}
    \item Different formats;
    \item Different messengers;
    \item Common metadata
  \end{itemize}
\end{itemize}
}
% \begin{columns}
% \begin{column}{0.5\textwidth}
% Data types:
%   \begin{itemize}
%     \item Raw detector readouts;
%     \item Pre-analyzed events;
%     \item Metadata
%   \end{itemize}
% \end{column}
% \begin{column}{0.5\textwidth}  %%<--- here
%  Data structure:
%   \begin{itemize}
%     \item Different formats;
%     \item Different messengers;
%     \item Common metadata
%   \end{itemize}
% \end{column}
% \end{columns}

% \begin{tabular}{|c|c|} \hline
% Data types & Data structure \\ \hline
% \begin{itemize}
%  \item r1 &  \item r2 \\
%  \item r3 &  \item r4 \\ \hline
%   \end{itemize}
% \end{tabular}


% \vspace{2em}
% \begin{minipage}[t]{0.4\textwidth}
% Data types:
%   \begin{itemize}
%     \item Raw detector readouts;
%     \item Pre-analyzed events;
%     \item Metadata;
%   \end{itemize}
% \end{minipage}
% \hfill
% \begin{minipage}[t]{0.4\textwidth}
%  Data structure:
%   \begin{itemize}
%     \item Different formats;
%     \item Different messengers;
%     \item Common metadata;
%   \end{itemize}
% \end{minipage}


% \begin{itemize}
%   \item Data types:
%   \begin{itemize}
%     \item Raw detector readouts;
%     \item Pre-analyzed events;
%     \item Metadata;
%   \end{itemize}
%   \item Data structure:
%   \begin{itemize}
%     \item Different formats;
%     \item Different messengers;
%     \item Common metadata;
%   \end{itemize}
% \end{itemize}

Our approach:
\begin{itemize}
 \item It is proposed to store unique event id and metadata in the unified database
 \item With growing data sizes, distribured storage for events could be useful
\end{itemize}
\end{frame}

% \begin{tabular*}{1\textwidth}{p{0.45\textwidth}@{\extracolsep{\fill}}p{0.45\textwidth}}
% \hline\multicolumn{2}{c}{Location} \\
% % Experiments: remote locations with no or limited internet access &
% % Servers: data are transferred periodically on tapes or disks \\
% % \hline\multicolumn{2}{c}{Data} \\
% % Raw detector readouts: analyzed offline, not stored &
% % Pre-analyzed events: stored on servers \\
% % \hline\multicolumn{2}{c}{Different \& common} \\
% % Each experiment has its own detectors and provides its own format of events &
% % Events share \emph{common metadata} (e.g.\ time, location, atmospheric conditions) \\
% \hline\multicolumn{2}{c}{Storage} \\
% It is proposed to store unique event id and metadata in the unified database &
% With growing data sizes, distribured storage for events could be useful \\
% \hline
% \end{tabular*}

% \begin{frame}{Data storage}
% \begin{itemize}
%   \item Some experiments (in our case, TUNKA) are situated at remote locations with no or limited internet access, raw data are transferred periodically to servers on tapes or disks
%   \item Raw data are pre-analyzed, so-called ``direct'' observables ($e$, $\mu$, $\gamma$, $\hat{C}$, radio, etc.) are obtained, events are stored on servers
%   \item Each experiment has its own detectors and provides its own format of events
%   \item Events share \emph{common metadata} (e.g.\ time, location, atmospheric conditions)
%   \item It is proposed to store unique event id and metadata in the unified database
%   \item With growing data sizes, distribured storage for events could be useful
% \end{itemize}
% \end{frame}

\begin{frame}{Proposed cosmic-ray metadata structure}
\vspace{-1.5em}
\begin{center}
\includegraphics[width=0.82\textwidth]{pics/metadata.eps}
\end{center}
\end{frame}

\begin{frame}{Data analysis}
\begin{itemize}
  \item Software for data analysis depends on a particular experiment
  \begin{itemize}
    \item Problem: It may even require dedicated system environment
    \concl{Solution: Virtualization could be useful}
  \end{itemize}
  \item Data analysis requires huge amounts of input data
  \begin{itemize}
    \item Problem: It is often more optimal to perform it on the same site the data are stored
    \concl{Solution: Job management could handle the task}
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Simulation}
\centering
\begin{tabular*}{1\textwidth}{c@{~~~$\Rightarrow$~~~}c}
\multicolumn{1}{c}{\textbf{Feature}} &
\multicolumn{1}{c}{\textbf{Consequence}} \\ \hline
\cellbox{The software for EAS simulation (e.g.\ KORSIKA) does not depend on a particular experiment} &
\cellbox{Simulations require standartized system environment} \\
\cellbox{
  Simulations require small amounts of input data

  Simulations can be done independently for different events
} &
\cellbox{Simulations are easily scalable} \\
\cellbox{Simulations require a lot of computing resources} &
\cellbox{HPC sites are needed} \\ \hline
\end{tabular*}

\vspace{1ex}
\centering\textbf{\textcolor{kit-green100}{Distributed computing could be useful}} \\
\end{frame}

\begin{frame}{Distributed analysis and simulation scheme}
% \textcolor{red}{Схема~--- проверить!)}
\vspace{-1em}
\begin{center}
% \includegraphics[width=0.85\textwidth]{pics/KCDC_workflow_f1.png}
\includegraphics[width=0.85\textwidth]{pics/kcdc_scheme_k.png}
\end{center}
\end{frame}

% \begin{frame}{Mapping of observables between experiments}
%
% \textcolor{red}{Draw the sheme of the mapping!!! See the Kostunin's slide \#8}
%
% \begin{block}{Draft}
%   \begin{itemize}
%     \item Calibrations provided by experiments
%     \item Various models
%     \item Implementations are stored
%   \end{itemize}
% \end{block}
% \begin{center}
%   \includegraphics[width=0.7\textwidth]{pics/k8.pdf}
% \end{center}
% \end{frame}

% \begin{frame}{Access}
% \begin{block}{Draft}
%   \begin{itemize}
%     \item Benefits of open access
%     \item Education and outreach
%     \item Which infrastructure to use?
%   \end{itemize}
% \end{block}
% \end{frame}

% %CONCLUSION
\input{concl.tex}

% \appendix
% \beginbackup
%
% \begin{frame}[allowframebreaks]{References}
% \printbibliography
% \end{frame}
%
% \backupend

\end{document}
